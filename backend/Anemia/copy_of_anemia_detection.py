# -*- coding: utf-8 -*-
"""Copy of Anemia Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RiqjhVaQTCh1eX56c7bgDbUDv2YQ7cJT

Load and Preprocess the Data
"""

import numpy as np
import cv2
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define the dataset path
data_path = '/content/drive/MyDrive/Dataset'

# List all image filenames
all_files = [os.path.join(data_path, img) for img in os.listdir(data_path) if img.endswith('.jpg')]

# Create labels based on filenames
all_labels = [1 if 'img_1_' in img else 0 for img in all_files]

import matplotlib.pyplot as plt
anemic_count = all_labels.count(1)
non_anemic_count = all_labels.count(0)

# Create bar plot
labels = ['Anemic', 'Non-Anemic']
counts = [anemic_count, non_anemic_count]

plt.bar(labels, counts, color=['blue', 'green'])
plt.xlabel('Image Category')
plt.ylabel('Number of Images')
plt.title('Distribution of Anemic and Non-Anemic Images')
plt.show()

# Split dataset into training, validation, and test sets
train_files, test_files, train_labels, test_labels = train_test_split(all_files, all_labels, test_size=0.2, random_state=42)
train_files, val_files, train_labels, val_labels = train_test_split(train_files, train_labels, test_size=0.2, random_state=42)

# Convert file paths and labels to DataFrame
train_df = pd.DataFrame({'filename': train_files, 'label': train_labels})
val_df = pd.DataFrame({'filename': val_files, 'label': val_labels})
test_df = pd.DataFrame({'filename': test_files, 'label': test_labels})

# Convert labels to strings
train_df['label'] = train_df['label'].astype(str)
val_df['label'] = val_df['label'].astype(str)
test_df['label'] = test_df['label'].astype(str)

# Data augmentation and preprocessing for training
train_datagen = ImageDataGenerator(rescale=1./255,
                                   rotation_range=20,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True)

# Data preprocessing for validation and test
val_datagen = ImageDataGenerator(rescale=1./255)

"""Data Visualization"""

import matplotlib.pyplot as plt

# Visualize sample images from the training set
plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i + 1)
    img = cv2.imread(train_files[i])
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.imshow(img)
    plt.title(f"Label: {train_labels[i]}")
    plt.axis("off")
plt.show()

# Training History Visualization
def plot_history(history):
    plt.figure(figsize=(12, 4))

    # Plot training & validation accuracy values
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    # Plot training & validation loss values
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.show()

# Plot training history
plot_history(history)

# Function to apply Gaussian blur
def apply_gaussian_blur(images):
    blurred_images = []
    for img in images:
        blurred = cv2.GaussianBlur(img, (5, 5), 0)
        blurred_images.append(blurred)
    return np.array(blurred_images)

# Load and preprocess images
train_images = [cv2.imread(img_path) for img_path in train_files]
train_images = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in train_images]
train_images_blurred = apply_gaussian_blur(train_images)

# Convert images to numpy array
train_images_blurred = np.array(train_images_blurred)

# Flatten the blurred images
train_images_blurred_flattened = train_images_blurred.reshape(train_images_blurred.shape[0], -1)

# Naive Bayes
from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(train_images_blurred_flattened, train_labels)

# Logistic Regression
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(max_iter=10000)
lr.fit(train_images_blurred_flattened, train_labels)

# MobileNetV2
from tensorflow.keras.applications import MobileNetV2

# Define MobileNetV2 base model
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Create data generators
batch_size = 32
img_size = (224, 224)

train_generator = train_datagen.flow_from_dataframe(train_df,
                                                    x_col='filename',
                                                    y_col='label',
                                                    target_size=img_size,
                                                    batch_size=batch_size,
                                                    class_mode='binary')

val_generator = val_datagen.flow_from_dataframe(val_df,
                                                x_col='filename',
                                                y_col='label',
                                                target_size=img_size,
                                                batch_size=batch_size,
                                                class_mode='binary')

test_generator = val_datagen.flow_from_dataframe(test_df,
                                                 x_col='filename',
                                                 y_col='label',
                                                 target_size=img_size,
                                                 batch_size=batch_size,
                                                 class_mode='binary')



# Define CNN model architecture
model = tf.keras.models.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
epochs = 20
history = model.fit(train_generator,
                    validation_data=val_generator,
                    epochs=epochs,
                    verbose=1)

# Evaluate the model on test data
test_loss, test_acc = model.evaluate(test_generator)
print(f"Test accuracy: {test_acc * 100:.2f}%")

# Save the trained model
model.save('/content/drive/MyDrive/model.h5')

# Print model summary
model.summary()